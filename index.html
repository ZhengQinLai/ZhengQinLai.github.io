<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Zhengqin Lai(赖正勤)的主页</title>
    <meta name="description" content="Academic homepage of Zhengqin Lai — Ph.D. student focusing on lifelong learning for embodied intelligence." />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Cormorant+Garamond:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
      :root {
        --bg: #0b0b0b;
        --text: #e8e8e8;
        --muted: #b7b7b7;
        --accent: #f5d200; /* rich yellow */
        --accent-weak: #3a3000;
        --card: #121212;
        --border: #222;
        --maxw: 980px;
      }
      * { box-sizing: border-box; }
      html, body { margin: 0; padding: 0; background: var(--bg); color: var(--text); }
      body { font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; font-size: 16px; line-height: 1.65; }
      a { color: var(--accent); text-decoration: none; }
      a:hover { text-decoration: underline; }

      /* Side decorative panels */
      .side-decor { position: fixed; top: 0; bottom: 0; width: 180px; pointer-events: none; z-index: 0; opacity: 0.22; }
      .side-left { left: 0; }
      .side-right { right: 0; transform: scaleX(-1); }
      .side-decor {
        background:
          /* soft glows */
          radial-gradient(120px 120px at 35% 14%, rgba(245,210,0,0.18), transparent 60%),
          radial-gradient(100px 100px at 65% 78%, rgba(245,210,0,0.14), transparent 60%),
          /* diagonal accents */
          repeating-linear-gradient(45deg, rgba(245,210,0,0.10) 0 10px, transparent 10px 20px),
          /* dotted grid */
          radial-gradient(rgba(245,210,0,0.16) 1px, transparent 1.5px) 0 0 / 18px 18px,
          /* subtle fade */
          linear-gradient(to right, rgba(0,0,0,0.7), rgba(0,0,0,0));
        -webkit-mask-image: linear-gradient(to right, black 70%, transparent 100%);
                mask-image: linear-gradient(to right, black 70%, transparent 100%);
      }
      @media (max-width: 920px) { .side-decor { display: none; } }

      .wrap { max-width: var(--maxw); margin: 0 auto; padding: 28px 18px 80px; position: relative; z-index: 1; }
      header { display: grid; grid-template-columns: 1fr 200px; gap: 28px; align-items: center; padding: 22px 0 10px; border-bottom: 1px solid var(--border); position: relative; z-index: 1; }
      @media (max-width: 740px) { header { grid-template-columns: 1fr; } }
      .name { font-family: "Cormorant Garamond", Georgia, serif; font-weight: 600; letter-spacing: 0.3px; font-size: 40px; margin: 0 0 8px; }
      .subtitle { margin: 0; color: var(--muted); font-size: 15px; }
      .contact { margin-top: 10px; display: flex; flex-wrap: wrap; gap: 12px; align-items: center; }
      .badge { display: inline-flex; align-items: center; gap: 8px; padding: 7px 12px; border: 1px solid var(--border); border-radius: 999px; background: linear-gradient(180deg, #101010, #0c0c0c); color: var(--text); font-size: 14px; }
      .badge .dot { width: 8px; height: 8px; border-radius: 50%; background: var(--accent); box-shadow: 0 0 0 3px var(--accent-weak); }
      .portrait { width: 180px; height: 180px; border-radius: 16px; overflow: hidden; border: 1px solid var(--border); background: #0f0f0f; }
      .portrait img { width: 100%; height: 100%; object-fit: cover; display: block; filter: saturate(0.95) contrast(1.02); }
      main { display: grid; grid-template-columns: 1fr; gap: 30px; margin-top: 24px; }
      section { padding: 18px 0 0; }
      .sec-title { font-family: "Cormorant Garamond", Georgia, serif; font-weight: 600; letter-spacing: 0.2px; font-size: 26px; margin: 12px 0 14px; color: var(--text); }
      .accent-bar { height: 3px; width: 56px; background: var(--accent); border-radius: 3px; box-shadow: 0 0 0 4px var(--accent-weak); }
      .card { background: var(--card); border: 1px solid var(--border); border-radius: 14px; padding: 18px; }
      .about p { margin: 0; font-size: 16px; color: var(--text); }
      .list { display: grid; gap: 14px; margin: 10px 0 0; padding: 0; list-style: none; }
      .pub { padding: 14px; border: 1px solid var(--border); border-radius: 12px; background: #0f0f0f; }
      .pub .title { font-weight: 600; color: var(--text); margin: 0 0 6px; }
      .pub .authors { margin: 0; color: var(--muted); font-size: 14px; }
      .pub .meta { margin: 6px 0 0; color: var(--muted); font-size: 13px; }
      .pub .links a { margin-right: 10px; font-size: 13px; }
      .awards li { padding: 12px 14px; border: 1px dashed var(--border); border-radius: 10px; background: #0e0e0e; }
      footer { margin-top: 40px; padding-top: 18px; border-top: 1px solid var(--border); color: var(--muted); font-size: 13px; }

      /* Language toggle */
      .lang-toggle { display: inline-flex; border: 1px solid var(--border); border-radius: 999px; overflow: hidden; background: #0e0e0e; margin-left: 6px; }
      .lang-toggle button { appearance: none; border: 0; background: transparent; color: var(--text); padding: 6px 10px; font-size: 13px; cursor: pointer; }
      .lang-toggle button.active { background: var(--accent); color: #111; font-weight: 600; }

      /* Tiny corner accents */
      .wrap::before, .wrap::after {
        content: ""; position: fixed; width: 10px; height: 10px; border-radius: 50%;
        background: var(--accent); filter: saturate(1.1); box-shadow: 0 0 0 6px var(--accent-weak), 0 0 22px rgba(245,210,0,0.2);
        z-index: 1; opacity: 0.9;
      }
      .wrap::before { left: 22px; top: 22px; }
      .wrap::after { right: 22px; bottom: 22px; }

      /* Timeline */
      .timeline-list { position: relative; list-style: none; margin: 10px 0 0; padding: 0 0 0 56px; }
      .timeline-list::before { content: ""; position: absolute; left: 28px; top: 0; bottom: 0; width: 2px; background: var(--border); }
      .tl-item { position: relative; padding: 12px 0 12px; }
      .tl-item .tl-marker { position: absolute; left: 21px; top: 26px; width: 14px; height: 14px; border-radius: 50%; background: var(--accent); box-shadow: 0 0 0 4px var(--accent-weak); }
      .tl-content { background: #0f0f0f; border: 1px solid var(--border); border-radius: 10px; padding: 12px 14px; }
      .tl-range { color: var(--text); font-weight: 600; margin: 0 0 6px; }
      .tl-role { color: var(--text); font-weight: 600; margin: 0 2px 2px 0; }
      .tl-major, .tl-place { color: var(--muted); font-size: 14px; margin: 0; }
    </style>
  </head>
  <body>
    <div class="side-decor side-left" aria-hidden="true"></div>
    <div class="side-decor side-right" aria-hidden="true"></div>
    <div class="wrap">
      <header>
        <div>
          <h1 class="name" data-i18n="name">Zhengqin Lai</h1>
          <p class="subtitle" data-i18n="subtitle">Ph.D. student, Computer Science — Harbin Institute of Technology (Shenzhen)</p>
          <div class="contact">
            <a class="badge" href="mailto:quenlenu@gmail.com" aria-label="email">
              <span class="dot"></span>
              <span>quenlenu@gmail.com</span>
            </a>
            <a class="badge" href="https://scholar.google.com.hk/citations?user=YuqWRrUAAAAJ&hl=zh-CN" target="_blank" rel="noopener" data-i18n="scholar">Google Scholar</a>
            <span class="lang-toggle" role="group" aria-label="Language toggle">
              <button type="button" data-lang="en" class="active" aria-pressed="true">EN</button>
              <button type="button" data-lang="zh" aria-pressed="false">中文</button>
            </span>
          </div>
        </div>
        <div class="portrait">
          <img id="portrait-img" src="img/self.png" alt="Portrait of Zhengqin Lai" />
        </div>
      </header>

      <main>
        <section class="about card">
          <div class="accent-bar" aria-hidden="true"></div>
          <h2 class="sec-title" data-i18n="about_title">About</h2>
          <p data-i18n="about_body">
            I am a second-year CS Ph.D. student at Harbin Institute of Technology (Shenzhen). My research interests focus on lifelong learning for embodied intelligence.
          </p>
        </section>

        <section class="timeline card">
          <div class="accent-bar" aria-hidden="true"></div>
          <h2 class="sec-title" data-i18n="timeline_title">Timeline</h2>
          <ul class="timeline-list">
            <li class="tl-item">
              <div class="tl-content">
                <p class="tl-range" data-i18n="tl2_range">2024 — Present</p>
                <p class="tl-role" data-i18n="tl2_role">Ph.D. Student</p>
                <p class="tl-major" data-i18n="tl2_major">Computer Science</p>
                <p class="tl-place" data-i18n="tl2_place">Harbin Institute of Technology (Shenzhen)</p>
              </div>
            </li>
            <li class="tl-item">
              <div class="tl-content">
                <p class="tl-range" data-i18n="tl1_range">2020 — 2024</p>
                <p class="tl-role" data-i18n="tl1_role">Undergraduate Student</p>
                <p class="tl-major" data-i18n="tl1_major">Computer Science and Technology</p>
                <p class="tl-place" data-i18n="tl1_place">Harbin Institute of Technology</p>
              </div>
            </li>
          </ul>
        </section>

        <section class="research card">
          <div class="accent-bar" aria-hidden="true"></div>
          <h2 class="sec-title" data-i18n="research_title">Research</h2>
          <p data-i18n="research_body">
            I pursue a single thread of lifelong and incremental learning across multimodal perception and affective computing. My recent work spans open-vocabulary multimodal emotion recognition (Agent-MER), incremental protocols for micro-expression recognition, robust multimodal modeling for sentiment understanding, and data-efficient “free-lunch” enhancements for crowd counting. My long-term goal is to build embodied agents that acquire skills continuously in real environments.
          </p>
        </section>

        <section class="publications card">
          <div class="accent-bar" aria-hidden="true"></div>
          <h2 class="sec-title" data-i18n="pubs_title">Selected Publications</h2>
          <ul class="list">
            <!-- First-author papers first -->
            <li class="pub">
              <p class="title">Agent-MER: A Cognitive Agent with Hierarchical Deliberation for Open-Vocabulary Multimodal Emotion Recognition</p>
              <p class="authors"><strong>Zhengqin Lai</strong>, Zhilin Zhu, Xiaopeng Hong*, Yaowei Wang</p>
              <p class="meta">Proceedings of the ACM International Conference on Multimedia (ACM MM), 2025</p>
              <p class="links"></p>
            </li>
            <li class="pub">
              <p class="title">A Benchmark for Incremental Micro-expression Recognition</p>
              <p class="authors"><strong>Zhengqin Lai</strong>, Xiaopeng Hong*, Yabin Wang, Xiaobai Li</p>
              <p class="meta">arXiv:2501.19111, 2025-01-31</p>
              <p class="links"><a href="https://arxiv.org/abs/2501.19111" target="_blank" rel="noopener">arXiv</a></p>
            </li>
            <li class="pub">
              <p class="title">Multimodal Blockwise Transformer for Robust Sentiment Recognition</p>
              <p class="authors"><strong>Zhengqin Lai</strong>, Xiaopeng Hong*, Yabin Wang</p>
              <p class="meta">Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing (MRAC), 2024</p>
              <p class="links"></p>
            </li>
            <!-- Co-authored (non-first) after -->
            <li class="pub">
              <p class="title">Free Lunch Enhancements for Multi-modal Crowd Counting</p>
              <p class="authors">Haoliang Meng, Xiaopeng Hong*, <strong>Zhengqin Lai</strong>, Miao Shang</p>
              <p class="meta">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
              <p class="links"></p>
            </li>
          </ul>
        </section>

        <section class="awards card">
          <div class="accent-bar" aria-hidden="true"></div>
          <h2 class="sec-title" data-i18n="awards_title">Honors & Awards</h2>
          <ul class="list">
            <li data-i18n="award1">IJCAI @ MER 2024 — NOISE Track, Rank 3</li>
            <li data-i18n="award2">ACM MM @ MER 2025 — FG Track, Rank 1</li>
          </ul>
        </section>
      </main>

      <footer>
        <span id="footer-updated">Last updated: Oct 2025 • Theme: black + yellow • Built for GitHub Pages</span>
      </footer>
    </div>
    <script>
      (function() {
        const i18n = {
          en: {
            name: "Zhengqin Lai",
            subtitle: "Ph.D. student, Computer Science — Harbin Institute of Technology (Shenzhen)",
            scholar: "Google Scholar",
            site_title: "Zhengqin Lai (赖正勤) — Academic Homepage",
            alt_portrait: "Portrait of Zhengqin Lai",
            about_title: "About",
            about_body: "I am a second-year CS Ph.D. student at Harbin Institute of Technology (Shenzhen). My research interests focus on lifelong learning for embodied intelligence.",
            research_title: "Research",
            research_body: "I pursue a single thread of lifelong and incremental learning across multimodal perception and affective computing. My recent work spans open-vocabulary multimodal emotion recognition (Agent-MER), incremental protocols for micro-expression recognition, robust multimodal modeling for sentiment understanding, and data-efficient ‘free-lunch’ enhancements for crowd counting. My long-term goal is to build embodied agents that acquire skills continuously in real environments.",
            pubs_title: "Selected Publications",
            timeline_title: "Timeline",
            tl1_range: "2020 — 2024",
            tl1_role: "Undergraduate Student",
            tl1_major: "Computer Science and Technology",
            tl1_place: "Harbin Institute of Technology",
            tl2_range: "2024 — Present",
            tl2_role: "Ph.D. Student",
            tl2_major: "Computer Science",
            tl2_place: "Harbin Institute of Technology (Shenzhen)",
            awards_title: "Honors & Awards",
            award1: "IJCAI @ MER 2024 — NOISE Track, Rank 3",
            award2: "ACM MM @ MER 2025 — FG Track, Rank 1",
          },
          zh: {
            name: "赖正勤",
            subtitle: "计算机科学博士生，哈尔滨工业大学（深圳）",
            scholar: "谷歌学术",
            site_title: "Zhengqin Lai(赖正勤)的主页",
            alt_portrait: "赖正勤的照片",
            about_title: "简介",
            about_body: "我目前是哈尔滨工业大学（深圳）计算机科学专业博士二年级生，研究方向聚焦于具身智能的终身学习。",
            research_title: "研究兴趣",
            research_body: "我的研究以增量/终身学习为主线，贯穿多模态感知与情感计算。近期工作涵盖开放词汇多模态情感识别（Agent-MER）、微表情识别的增量评测基准、面向情感理解的鲁棒多模态建模，以及在群体计数中提升泛化与数据效率的“免费午餐”增强方法。长期目标是在真实具身环境中构建能够持续习得技能的智能体。",
            pubs_title: "代表性论文",
            timeline_title: "时间线",
            tl1_range: "2020 — 2024",
            tl1_role: "本科生",
            tl1_major: "计算机科学与技术",
            tl1_place: "哈尔滨工业大学",
            tl2_range: "2024 — 至今",
            tl2_role: "博士研究生",
            tl2_major: "计算机科学",
            tl2_place: "哈尔滨工业大学（深圳）",
            awards_title: "荣誉与奖励",
            award1: "IJCAI @ MER 2024 — NOISE 赛道 第三名",
            award2: "ACM MM @ MER 2025 — FG 赛道 第一名",
          }
        };

        function formatUpdated(lang) {
          const d = new Date();
          const enMonths = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];
          if (lang === 'zh') {
            return `最近更新：${d.getFullYear()}年${d.getMonth()+1}月 • 主题：黑黄 • GitHub Pages`;
          } else {
            return `Last updated: ${enMonths[d.getMonth()]} ${d.getFullYear()} • Theme: black + yellow • Built for GitHub Pages`;
          }
        }

        function setLang(lang) {
          const dict = i18n[lang] || i18n.en;
          document.querySelectorAll('[data-i18n]').forEach(el => {
            const key = el.getAttribute('data-i18n');
            if (dict[key]) el.textContent = dict[key];
          });
          // Page title and portrait alt text
          if (dict.site_title) { document.title = dict.site_title; }
          const portrait = document.getElementById('portrait-img');
          if (portrait && dict.alt_portrait) { portrait.setAttribute('alt', dict.alt_portrait); }
          document.getElementById('footer-updated').textContent = formatUpdated(lang);
          document.documentElement.lang = (lang === 'zh') ? 'zh-Hans' : 'en';
          document.querySelectorAll('.lang-toggle button').forEach(btn => {
            const on = btn.getAttribute('data-lang') === lang;
            btn.classList.toggle('active', on);
            btn.setAttribute('aria-pressed', on ? 'true' : 'false');
          });
          try { localStorage.setItem('lang', lang); } catch {}
        }

        document.querySelectorAll('.lang-toggle button').forEach(btn => {
          btn.addEventListener('click', () => setLang(btn.getAttribute('data-lang')));
        });

        const initial = (function(){ try { return localStorage.getItem('lang') || 'en'; } catch { return 'en'; } })();
        setLang(initial);
      })();
    </script>
  </body>
  </html>
